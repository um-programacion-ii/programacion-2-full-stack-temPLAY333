# Proxy - Servicio Intermedio

Servicio proxy intermedio entre el **BackEnd** y los servicios externos de la c√°tedra (API HTTP, Kafka, Redis).

## üéØ Arquitectura: H√≠brida S√≠ncrona/As√≠ncrona

El Proxy opera en **dos modos simult√°neos**:

### 1. **Modo S√≠ncrono** (HTTP ‚Üí HTTP)
- Los endpoints REST del Proxy **forwardean** llamadas HTTP a la API de la c√°tedra
- Devuelven respuestas **s√≠ncronas inmediatas** al cliente
- Opcionalmente notifican al Backend v√≠a webhook con la respuesta HTTP

### 2. **Modo As√≠ncrono** (Kafka ‚Üí Webhook)
- Escucha el topic de Kafka de la c√°tedra (`eventos-actualizacion`)
- Detecta eventos as√≠ncronos (ventas completadas, asientos bloqueados, etc.)
- Notifica al Backend v√≠a webhook HTTP con el evento de Kafka

**‚ö†Ô∏è IMPORTANTE PARA EL BACKEND**: Recibir√°s notificaciones de **ambos canales**:
- Respuestas HTTP s√≠ncronas (opcional, si el Proxy las reenv√≠a)
- Eventos as√≠ncronos de Kafka (siempre, cuando Kafka est√° habilitado)

## üîå Servicios Externos (C√°tedra)

### API HTTP
- **Base URL**: `http://192.168.194.250:8080`
- **Autenticaci√≥n**: JWT Bearer Token
  - El Proxy se autentica autom√°ticamente al iniciar usando credenciales configuradas
  - Renueva el token autom√°ticamente cuando expira
  - Config: `app.catedra.username` y `app.catedra.password`

### Kafka (Consumer)
- **Bootstrap Servers**: `192.168.194.250:9092`
- **Topic**: `eventos-actualizacion`
- **Group ID**: `proxy-grupo`
- **‚ö†Ô∏è Puede deshabilitarse**: `spring.kafka.enabled=false` (√∫til para desarrollo local)
- **Consumer**: `EventoCambioConsumer` detecta tipo de evento y notifica al Backend

### Redis (Solo Lectura)
- **Host**: `192.168.194.250:6379`
- **Keys**: `evento_<ID>` con JSON `{"eventoId": ..., "asientos": [...]}`
- **Uso**: Cache de estado de asientos (bloqueados/vendidos)
- **‚ö†Ô∏è Puede deshabilitarse**: `spring.data.redis.enabled=false`

## üì° Endpoints Implementados (Proxy ‚Üí C√°tedra)

**Base URL del Proxy**: `http://localhost:8080`

### UserProxyController (`/api/users`)

#### POST `/api/users/login`
Login de usuario.
- **URL Externa C√°tedra**: `POST /api/authenticate`
- **Entrada**: `LoginRequestDTO { username, password }`
- **Salida**: `LoginResponseDTO { id_token }`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata

---

### EventoProxyController (`/api/eventos`)

#### GET `/api/eventos/resumidos`
Listado de eventos (datos resumidos).
- **URL Externa C√°tedra**: `GET /api/endpoints/v1/eventos-resumidos`
- **Salida**: `List<EventoResumenDTO>`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata

#### GET `/api/eventos`
Listado completo de eventos (con todos los datos).
- **URL Externa C√°tedra**: `GET /api/endpoints/v1/eventos`
- **Salida**: `List<EventoDTO>`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata

#### GET `/api/eventos/{id}`
Datos completos de un evento espec√≠fico.
- **URL Externa C√°tedra**: `GET /api/endpoints/v1/evento/{id}`
- **Salida**: `EventoDetalleDTO`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata

#### POST `/api/eventos/{id}/bloquear-asientos`
Bloqueo de asientos por evento.
- **URL Externa C√°tedra**: `POST /api/endpoints/v1/bloquear-asientos`
- **Entrada**: `BloquearAsientosRequestDTO { eventoId, asientos[] }`
- **Salida**: `BloquearAsientosResponseDTO { resultado, mensaje }`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata
- **Notificaci√≥n As√≠ncrona**: ‚ö° Puede llegar evento `ASIENTOS_BLOQUEADOS` v√≠a Kafka despu√©s

#### GET `/api/eventos/{id}/asientos-estado`
Estado actual de los asientos de un evento (desde Redis).
- **Origen**: Redis c√°tedra (key `evento_{id}`)
- **Salida**: `List<AsientoEstadoDTO> { fila, columna, estado }`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata
- **Nota**: Solo retorna asientos bloqueados/vendidos (el resto se asume disponible)

---

### VentaProxyController (`/api/ventas`)

#### POST `/api/ventas/realizar`
Venta de asientos por un evento.
- **URL Externa C√°tedra**: `POST /api/endpoints/v1/realizar-venta`
- **Entrada**: `RealizarVentaRequestDTO { eventoId, asientos[], username }`
- **Salida**: `RealizarVentaResponseDTO { resultado, mensaje }`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata (√©xito/fallo del request)
- **Notificaci√≥n As√≠ncrona**: ‚ö° Cuando la venta se completa, llega evento `VENTA_COMPLETADA` v√≠a Kafka

#### GET `/api/ventas`
Listado completo de ventas por alumno (datos resumidos).
- **URL Externa C√°tedra**: `GET /api/endpoints/v1/listar-ventas`
- **Salida**: `List<VentaResumenDTO>`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata

#### GET `/api/ventas/{id}`
Ver datos de una venta particular.
- **URL Externa C√°tedra**: `GET /api/endpoints/v1/listar-venta/{id}`
- **Salida**: `VentaDTO`
- **Respuesta S√≠ncrona**: ‚úÖ Inmediata

---

## üîî Notificaciones al Backend (Webhook)

### ‚ö†Ô∏è ENDPOINT QUE EL BACKEND DEBE IMPLEMENTAR

El Backend **DEBE** implementar el siguiente endpoint para recibir notificaciones del Proxy:

```
POST /api/webhooks/evento-cambio
Content-Type: application/json
Authorization: Bearer {token}  (opcional)
```

**Request Body**: `BackendNotificacionDTO` (ver estructura abajo)

### Flujo de Notificaci√≥n

```
[Kafka C√°tedra] ‚Üí [EventoCambioConsumer] ‚Üí [NotificadorBackendService] ‚Üí [Backend Webhook]
```

### Configuraci√≥n del Endpoint

El Proxy construye la URL completa concatenando:
- `app.backend.base-url` (default: `http://localhost:8081`)
- `app.backend.webhook-path` (default: `/api/webhooks/evento-cambio`)

**URL Completa por Defecto**: `http://localhost:8081/api/webhooks/evento-cambio`

**Headers**:
- `Content-Type: application/json`
- `Authorization: Bearer {app.backend.token}` (solo si est√° configurado)

**M√©todo**: `POST`

### DTO de Notificaci√≥n: `BackendNotificacionDTO`

```json
{
  "timestamp": "2025-12-10T19:30:00Z",
  "topic": "VENTA_COMPLETADA",
  "partition": 0,
  "offset": 12345,
  "key": "evento-1",
  "payload": "{\"ventaId\":123,\"eventoId\":1,\"asientos\":[...],\"fechaVenta\":\"...\"}"
}
```

**Campos**:
- `timestamp`: Momento en que el Proxy recibe/procesa el evento
- `topic`: Tipo l√≥gico del evento (ver tipos soportados abajo)
- `partition`, `offset`, `key`: Metadata de Kafka (null si viene de HTTP)
- `payload`: JSON **crudo** del evento (string, debe parsearse en el Backend)

### Tipos de Eventos Soportados

El Proxy **detecta autom√°ticamente** el tipo analizando la estructura del JSON:

| `topic` | Estructura JSON | Origen | Descripci√≥n |
|---------|----------------|--------|-------------|
| `VENTA_COMPLETADA` | `{ventaId, eventoId, asientos, fechaVenta}` | Kafka | Venta procesada exitosamente |
| `ASIENTOS_BLOQUEADOS` | `{eventoId, asientos, bloqueadoHasta}` | Kafka | Asientos reservados temporalmente |
| `EVENTO_CAMBIADO` | `{eventoId, tipoCambio}` | Kafka | Modificaci√≥n en evento (nombre, fecha, etc.) |
| `UNKNOWN` | Otros | Kafka | Estructura no reconocida |

### Ejemplo de Implementaci√≥n en el Backend

```java
@RestController
@RequestMapping("/api/webhooks")
public class WebhookController {
    
    @PostMapping("/evento-cambio")
    public ResponseEntity<Void> recibirEventoCambio(
            @RequestHeader(value = "Authorization", required = false) String authHeader,
            @RequestBody BackendNotificacionDTO notificacion) {
        
        // 1. Validar token si est√° configurado
        // if (authHeader != null && !validarToken(authHeader)) {
        //     return ResponseEntity.status(401).build();
        // }
        
        // 2. Procesar seg√∫n el tipo de evento
        switch (notificacion.getTopic()) {
            case "VENTA_COMPLETADA":
                procesarVentaCompletada(notificacion.getPayload());
                break;
            case "ASIENTOS_BLOQUEADOS":
                procesarAsientosBloqueados(notificacion.getPayload());
                break;
            case "EVENTO_CAMBIADO":
                procesarEventoCambiado(notificacion.getPayload());
                break;
            default:
                log.warn("Tipo de evento desconocido: {}", notificacion.getTopic());
        }
        
        return ResponseEntity.ok().build();
    }
    
    private void procesarVentaCompletada(String payloadJson) {
        // El payload es un JSON string, debe parsearse
        // Ejemplo: {"ventaId":123,"eventoId":1,"asientos":[...],"fechaVenta":"..."}
        ObjectMapper mapper = new ObjectMapper();
        VentaCompletadaEventoDTO venta = mapper.readValue(payloadJson, VentaCompletadaEventoDTO.class);
        // ... tu l√≥gica de negocio
    }
}
```

**Importante**: 
- El endpoint **NO debe devolver error** para evitar que el Proxy reintente
- Es responsabilidad del Backend manejar errores internamente
- El `payload` es un **String JSON** que debe parsearse, no un objeto

### Componentes del Proxy

#### `EventoCambioConsumer`
- **Listener Kafka**: Escucha el topic `eventos-actualizacion`
- **Group ID**: `proxy-grupo`
- **Detecci√≥n de tipo**: Analiza estructura JSON (fallback si no hay header de tipo)
- **Manejo de errores**: Log y contin√∫a (no rompe el consumidor)

#### `NotificadorBackendService`
- **WebClient**: Llamadas HTTP reactivas al Backend
- **Fire-and-Forget**: No espera respuesta del Backend ni reintenta
- **Timeout**: Default de WebClient (30s)
- **Error handling**: Log de error, no propaga excepci√≥n

---

## üóÑÔ∏è Acceso a Redis (Estado de Asientos)

### `AsientoRedisService`
- **Prop√≥sito**: Leer estado actual de asientos desde cache de la c√°tedra
- **Template**: `StringRedisTemplate`
- **Key pattern**: `evento_{eventoId}`
- **Formato JSON**:
  ```json
  {
    "eventoId": 1,
    "asientos": [
      {"fila": 1, "columna": 3, "estado": "Bloqueado"},
      {"fila": 2, "columna": 5, "estado": "Vendido"}
    ]
  }
  ```
- **Endpoint**: `GET /api/eventos/{id}/asientos-estado`
- **Salida**: `List<AsientoEstadoDTO>` ordenada por fila y columna
- **Nota**: Solo se guardan asientos **bloqueados o vendidos**, el resto se asume disponible

---

## üõ†Ô∏è Tecnolog√≠as

- **Spring Boot 3.3.3**
  - `spring-boot-starter-web`: REST controllers
  - `spring-boot-starter-webflux`: WebClient reactivo
  - `spring-boot-starter-validation`: Validaci√≥n de DTOs
  - `spring-kafka`: Consumer de Kafka
  - `spring-data-redis`: Acceso a Redis
  - `spring-boot-starter-actuator`: Health checks y m√©tricas
- **Jackson**: Serializaci√≥n/deserializaci√≥n JSON
- **Lettuce**: Cliente Redis (async)
- **Maven**: Build y gesti√≥n de dependencias

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno Principales

```properties
# C√°tedra - API HTTP
APP_CATEDRA_BASE_URL=http://192.168.194.250:8080
APP_CATEDRA_USERNAME=usuario
APP_CATEDRA_PASSWORD=contrase√±a

# Backend - Webhook
APP_BACKEND_BASE_URL=http://localhost:8081
APP_BACKEND_WEBHOOK_PATH=/api/webhooks/evento-cambio
APP_BACKEND_TOKEN=opcional-bearer-token

# Kafka
APP_KAFKA_BOOTSTRAP_SERVERS=192.168.194.250:9092
APP_KAFKA_CONSUMER_GROUP=proxy-grupo
APP_KAFKA_CONSUMER_TOPIC=eventos-actualizacion
SPRING_KAFKA_ENABLED=true  # false para deshabilitar

# Redis
APP_REDIS_HOST=192.168.194.250
APP_REDIS_PORT=6379
```

### Perfiles de Spring

- **default**: Producci√≥n (todos los servicios habilitados)
- **dev**: Desarrollo local (Kafka y Redis deshabilitados)
- **integration**: Tests de integraci√≥n (servicios reales)
- **test**: Tests unitarios (todo mockeado)

---

## üöÄ Ejecuci√≥n

### Modo Producci√≥n (con todos los servicios)
```powershell
mvn spring-boot:run
```

### Modo Desarrollo (sin Kafka/Redis)
```powershell
mvn spring-boot:run -Dspring-boot.run.profiles=dev
```

O usar el script:
```powershell
.\ejecutar-proxy-dev.bat
```

### Deshabilitar solo Kafka
```powershell
mvn spring-boot:run -Dspring-boot.run.arguments="--spring.kafka.enabled=false"
```

### Health Check
```powershell
curl http://localhost:8080/actuator/health
```

---

## üß™ Testing

### Tests Unitarios (sin servicios externos)
```powershell
mvn test
```
- **Resultados**: 17 tests (EventoProxyController, UserProxyController, VentaProxyController, Services)
- **Mocks**: WebClient, Redis, NotificadorBackendService

### Tests de Integraci√≥n (requiere servicios de la c√°tedra)
```powershell
$env:APP_CATEDRA_USERNAME='usuario'
$env:APP_CATEDRA_PASSWORD='contrase√±a'
$env:APP_KAFKA_BOOTSTRAP_SERVERS='192.168.194.250:9092'
mvn verify -Pit-tests
```
- **Resultados**: 2 tests (ProxyIT: GET eventos resumidos, GET asientos estado)
- **Requiere**: Servicios de la c√°tedra accesibles desde la red

---

## üêõ Soluci√≥n de Problemas

### Error: `kafka:9092` no se puede resolver
**Problema**: El servidor Kafka de la c√°tedra se anuncia como `kafka:9092` pero tu m√°quina no resuelve ese hostname.

**Soluci√≥n 1** (Recomendada): Agregar entrada al archivo hosts
```powershell
# Ejecutar como Administrador
.\agregar-kafka-hosts.bat
```

O manual: Agregar a `C:\Windows\System32\drivers\etc\hosts`:
```
192.168.194.250 kafka
```

**Soluci√≥n 2**: Deshabilitar Kafka temporalmente
```powershell
mvn spring-boot:run -Dspring-boot.run.arguments="--spring.kafka.enabled=false"
```

### Error: Connection refused a servicios de la c√°tedra
**Problema**: Los servicios `192.168.194.250:8080/9092/6379` no est√°n accesibles desde tu red.

**Soluci√≥n**: Usar perfil dev (deshabilita Kafka/Redis)
```powershell
mvn spring-boot:run -Dspring-boot.run.profiles=dev
```

### Logs: "401 Unauthorized" al llamar a la c√°tedra
**Problema**: Token JWT expirado o credenciales incorrectas.

**Soluci√≥n**: El Proxy renueva autom√°ticamente el token. Verifica que las credenciales sean correctas en `.env` o variables de entorno.

---

## üìù Notas Arquitect√≥nicas

### Para el Backend Developer

1. **Sin Base de Datos Propia**: El Proxy es stateless, no persiste nada
2. **Webhooks son Fire-and-Forget**: El Proxy no espera respuesta del Backend
3. **DTOs Compartidos**: Los DTOs en `um.prog2.dto.*` pueden compartirse con el Backend (copiarlos o generar librer√≠a com√∫n)
4. **Modelo H√≠brido**:
   - **Operaciones de consulta (GET)**: 100% s√≠ncronas
   - **Operaciones de modificaci√≥n (POST)**: Respuesta s√≠ncrona + posible evento as√≠ncrono v√≠a Kafka
5. **El Backend debe procesar el `payload`**: Es un JSON string, no un objeto deserializado
6. **Idempotencia**: Kafka puede reenviar mensajes, considera usar `offset` + `partition` como ID √∫nico

### Respuesta a: "¬øEl Proxy pas√≥ de as√≠ncrono a s√≠ncrono?"

**No, el Proxy sigue siendo H√çBRIDO**:

- **Los endpoints HTTP son s√≠ncronos**: Llamas al Proxy, el Proxy llama a la c√°tedra, te devuelve la respuesta inmediatamente
- **Kafka sigue siendo as√≠ncrono**: Eventos de la c√°tedra llegan v√≠a Kafka al Proxy, que los reenv√≠a al Backend v√≠a webhook

**Ejemplo de flujo completo para una venta**:
1. Cliente ‚Üí `POST /api/ventas/realizar` ‚Üí Proxy
2. Proxy ‚Üí C√°tedra ‚Üí respuesta inmediata (√©xito/fallo)
3. Proxy ‚Üí Cliente (respuesta s√≠ncrona)
4. [Despu√©s, cuando la venta se procesa en la c√°tedra]
5. C√°tedra ‚Üí Kafka ‚Üí `VENTA_COMPLETADA`
6. Proxy (Kafka Consumer) ‚Üí Backend (webhook)

**El problema de Kafka que solucionamos**: Era un error de DNS donde el broker Kafka se anunciaba como `kafka:9092` pero la m√°quina no pod√≠a resolver ese hostname. Se soluciona agregando la entrada al archivo hosts de Windows o deshabilitando Kafka temporalmente.

### Estructura de Paquetes

```
um.prog2
‚îú‚îÄ‚îÄ config/           # WebClient, Kafka, Redis
‚îú‚îÄ‚îÄ dto/
‚îÇ   ‚îú‚îÄ‚îÄ autenticacion/
‚îÇ   ‚îú‚îÄ‚îÄ consultaventas/
‚îÇ   ‚îú‚îÄ‚îÄ evento/
‚îÇ   ‚îú‚îÄ‚îÄ notificacion/  # BackendNotificacionDTO ‚≠ê
‚îÇ   ‚îî‚îÄ‚îÄ venta/
‚îú‚îÄ‚îÄ messaging/         # EventoCambioConsumer ‚≠ê
‚îú‚îÄ‚îÄ service/
‚îÇ   ‚îú‚îÄ‚îÄ AsientoRedisService
‚îÇ   ‚îú‚îÄ‚îÄ AuthTokenService
‚îÇ   ‚îî‚îÄ‚îÄ NotificadorBackendService ‚≠ê
‚îî‚îÄ‚îÄ web/              # *ProxyController
```

‚≠ê = Componentes clave para integraci√≥n Backend

### Logging

- **Nivel INFO**: Operaciones principales, autenticaci√≥n, Kafka conectado/desconectado
- **Nivel DEBUG**: Request/response de cada operaci√≥n, contenido de mensajes Kafka
- **Nivel ERROR**: Fallos de conexi√≥n, errores de parsing, webhooks fallidos

Configurado para `um.prog2.*` en DEBUG para facilitar troubleshooting.
